{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6d87a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edc7a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d251633",
   "metadata": {},
   "source": [
    "# 02. Linear and Logistic Regression\n",
    "### Simple, yet powerful predictors\n",
    "* Regression – problem statement and motivation;\n",
    "* Ordinary least squares: method, simulated example, implementation on real data;\n",
    "* RANSAC – robust regression model;\n",
    "* Linear regression extensions: polynomial regression, multi-dimensional linear regression;\n",
    "* Classification – problem statement and motivation;\n",
    "* Logistic regression: method, simulated example, real data;\n",
    "* Regularization for regression and classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "433e15a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel is working..\n"
     ]
    }
   ],
   "source": [
    "print('Kernel is working..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ceb403",
   "metadata": {},
   "source": [
    "Logistic regression has \"Regression\" in it's name, but it does a classification. :D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b826af",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "Predict continuous values... and torture first-semester students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f644efe",
   "metadata": {},
   "source": [
    "* Regression - predicting continuous variable\n",
    "* Problem statement \n",
    "    * Given pairs of $ (x; y) $ points, create a model\n",
    "        * Input $ x $, output $ y $; **goal: predict $ y $ given $ x $**\n",
    "         * Under the assumption that $ y $ depends linearly on $ x $ (and nothing else)\n",
    "* Modelling function\n",
    "    * $\\tilde{y} = ax + b$\n",
    "    * Many samples: for each sample $ (x_{1}, y_{1}), ..., (x_{n}, y_{n}):$\n",
    "        * $ \\tilde{y_{i}} = ax_{i} + b, i \\in [1;n] $\n",
    "    * Many variables: $ \\tilde{y} = a_{1}x_{1} + a_{2}x_{2} + ... + a_{n}x_{n} + b \\equiv a^{T}X + b $\n",
    "        * Trick: $ a_{0} \\equiv b; x_{0} \\equiv 1 \\Rightarrow \\tilde{y} = a_{0}.1 + a_{1}x_{1} + ... + a_{n}x_{n} = a^{T}x $ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909f645a",
   "metadata": {},
   "source": [
    "Imagine that we have a matrix. One row is one observation, and one column is a feature (or attribute), so one cell is a variable for an observation. (Assume that the matrix is made out of numbers only). This matrix is what we call the `features`, and we use a `X` sighn for it. Sometimes the underlines show the rank. If there is one line bellow, it's a vector, and if there are two - it's a matrix. By a convention we would say, that the dimensions are n rows by m cols. For a result we would expect a vector `y` containing n rows by 1 col. So we say that we have a process, such as when we give it the data from `X` it producess the results of `y`.\n",
    "\n",
    "$$\n",
    "X_{n,m} = \n",
    "\\begin{pmatrix}\n",
    "a_{1,1} & a_{1,2} & \\cdots & a_{1,m} \\\\\n",
    "a_{2,1} & a_{2,2} & \\cdots & a_{2,m} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "a_{n,1} & a_{n,2} & \\cdots & a_{n,m} \n",
    "\\end{pmatrix} \n",
    "\\Rightarrow f(a_{n}) \\Rightarrow\n",
    "y_{1,n} = \\begin{bmatrix}\n",
    "a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{n} \\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4926ebf",
   "metadata": {},
   "source": [
    "No system can say for itself whether it is correct or not, someone from outside has to check it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef701634",
   "metadata": {},
   "source": [
    "Looking at the image above, we could see that we have a function $ f(a_{n})$ , well this is basically our model :D This function gives us a result, which we call `prediction`, $ \\tilde{y} $ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faedbc16",
   "metadata": {},
   "source": [
    "Our job is to make $ \\tilde{y} $ as similar as possible to $ y $ (approximate it)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad3ca6c",
   "metadata": {},
   "source": [
    "It's good to be able to think about data as points in n-dimentional space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c070e72c",
   "metadata": {},
   "source": [
    "To measure two points we could use Euclidian distance: $ d(p,q)^{2} = (q_{1} - p_{1})^{2} + (q_{2} - p_{2})^{2} $ or $ d(p,q) = \\sqrt{(q_{1} - p_{1})^{2} + (q_{2} - p_{2})^{2}} $ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ddb1a2",
   "metadata": {},
   "source": [
    "These \"points\" could tell us how similar are two data observations. But look, there is a difference between $ y_{i} $ and the predicted $ \\tilde{y_{i}} $, so we just subtract them - $ y_{i} - \\tilde{y_{i}}$. Here comes the next question, the result could be negative, that's why we could get the mode $ | y_{i} - \\tilde{y_{i}} |$  or get them as a square root $ (y_{i} - \\tilde{y_{i}})^{2} $. Now that becomes the difference of \"how much is one point far away from the predicted one\".\n",
    "\n",
    "$$ d_{i} = (y_{i} - \\tilde{y_{i}})^{2} $$\n",
    "\n",
    "But we do not care for only one observation, we are interested in all of them, so that's why we can get the sum of all of them, and after that divide it to the mean. It's also called Mean Square Error (MSE) or cost function. We usually use `J` for the MSE.\n",
    "$$ J := \\frac{1}{n} \\sum^{n - 1}_{i = 0} d_{i} \\equiv \\frac{1}{n} \\sum_{i} (y_{i} - \\tilde{y_{i}})^{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5ee314",
   "metadata": {},
   "source": [
    "Now we have a new goal: find \"the best model\", $ f(a_{n}) $. So let's define what is the best model: well, basically $ min(J) $. And suddenly we have a optimization task :D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02710112",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0c430",
   "metadata": {},
   "source": [
    "Date: 14.09.2023"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
